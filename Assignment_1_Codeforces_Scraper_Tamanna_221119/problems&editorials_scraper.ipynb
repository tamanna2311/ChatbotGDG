{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed31a48b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from selenium.webdriver import Chrome\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "import time\n",
    "import json\n",
    "import os\n",
    "\n",
    "# Path to ChromeDriver\n",
    "CHROMEDRIVER_PATH = \"/Users/chinmayanand/Documents/chromedriver-mac-arm64/chromedriver\"\n",
    "\n",
    "# Create folders for problems and editorials if they don't exist\n",
    "os.makedirs(\"problems\", exist_ok=True)\n",
    "os.makedirs(\"editorials\", exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3dbb15fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def configure_driver():\n",
    "    options = Options()\n",
    "    options.add_argument(\"--headless\")\n",
    "    options.add_argument(\"--no-sandbox\")\n",
    "    options.add_argument(\"--disable-dev-shm-usage\")\n",
    "    options.add_argument(\n",
    "        \"user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/131.0.6778.140 Safari/537.36\"\n",
    "    )\n",
    "    return Chrome(service=Service(CHROMEDRIVER_PATH), options=options)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d4c45d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_page_source(page_source, filename):\n",
    "    with open(filename, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(page_source)\n",
    "    print(f\"Saved page source to '{filename}'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "07d96d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_codeforces(url):\n",
    "    driver = configure_driver()\n",
    "    driver.get(url)\n",
    "    time.sleep(10)  # Allow time for the page to load\n",
    "\n",
    "    # Save page source for debugging\n",
    "    page_source = driver.page_source\n",
    "    save_page_source(page_source, \"debug_page_source.html\")\n",
    "    driver.quit()\n",
    "\n",
    "    soup = BeautifulSoup(page_source, \"html.parser\")\n",
    "\n",
    "    # Extract title\n",
    "    try:\n",
    "        title = soup.find(\"div\", class_=\"title\").text.strip()\n",
    "    except AttributeError:\n",
    "        title = \"Title not found\"\n",
    "\n",
    "    # Extract content based on the URL type\n",
    "    if \"problem\" in url:\n",
    "        try:\n",
    "            content = soup.find(\"div\", class_=\"problem-statement\").text.strip()\n",
    "        except AttributeError:\n",
    "            content = \"Content not found\"\n",
    "    else:  # Handle editorial pages\n",
    "        try:\n",
    "            content = soup.find(\"div\", class_=\"ttypography\").text.strip()\n",
    "        except AttributeError:\n",
    "            content = \"Content not found\"\n",
    "\n",
    "    # Extract tags\n",
    "    try:\n",
    "        tags = [tag.text.strip() for tag in soup.find_all(\"span\", class_=\"tag-box\")]\n",
    "    except AttributeError:\n",
    "        tags = []\n",
    "\n",
    "    # Determine folder and file naming based on URL\n",
    "    if \"problem\" in url:\n",
    "        folder = \"problems\"\n",
    "        problem_id = url.split(\"/\")[-2]  # Extract the problem ID, e.g., \"2029\"\n",
    "        problem_letter = url.split(\"/\")[-1]  # Extract the problem letter, e.g., \"D\"\n",
    "        problem_folder = os.path.join(folder, problem_id)\n",
    "        os.makedirs(problem_folder, exist_ok=True)  # Create a subfolder for the problem ID\n",
    "        json_path = f\"{problem_folder}/{problem_letter}.json\"\n",
    "        text_path = f\"{problem_folder}/{problem_letter}.txt\"\n",
    "    else:\n",
    "        folder = \"editorials\"\n",
    "        entry_id = url.split(\"/\")[-1]  # Use the entry ID for editorials\n",
    "        json_path = f\"{folder}/{entry_id}.json\"\n",
    "        text_path = f\"{folder}/{entry_id}.txt\"\n",
    "\n",
    "    # Save content and metadata\n",
    "    with open(json_path, \"w\", encoding=\"utf-8\") as json_file:\n",
    "        json.dump({\n",
    "            \"url\": url,\n",
    "            \"title\": title,\n",
    "            \"tags\": tags,\n",
    "            \"content\": content[:25000] + \"...\"\n",
    "        }, json_file, indent=4)\n",
    "    with open(text_path, \"w\", encoding=\"utf-8\") as text_file:\n",
    "        text_file.write(content)\n",
    "\n",
    "    print(f\"Scraped data saved to '{folder}' folder.\")\n",
    "    print(f\"JSON: {json_path}\")\n",
    "    print(f\"Text: {text_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc30a18f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Enter the Codeforces URL (or type 'exit' to quit): https://codeforces.com/problemset/problem/2046/A\n",
      "Saved page source to 'debug_page_source.html'.\n",
      "Scraped data saved to 'problems' folder.\n",
      "JSON: problems/2046/A.json\n",
      "Text: problems/2046/A.txt\n",
      "\n",
      "Enter the Codeforces URL (or type 'exit' to quit): https://codeforces.com/blog/entry/136908\n",
      "Saved page source to 'debug_page_source.html'.\n",
      "Scraped data saved to 'editorials' folder.\n",
      "JSON: editorials/136908.json\n",
      "Text: editorials/136908.txt\n",
      "\n",
      "Enter the Codeforces URL (or type 'exit' to quit): https://codeforces.com/problemset/problem/2046/B\n",
      "Saved page source to 'debug_page_source.html'.\n",
      "Scraped data saved to 'problems' folder.\n",
      "JSON: problems/2046/B.json\n",
      "Text: problems/2046/B.txt\n",
      "\n",
      "Enter the Codeforces URL (or type 'exit' to quit): https://codeforces.com/problemset/problem/2046/C\n",
      "Saved page source to 'debug_page_source.html'.\n",
      "Scraped data saved to 'problems' folder.\n",
      "JSON: problems/2046/C.json\n",
      "Text: problems/2046/C.txt\n",
      "\n",
      "Enter the Codeforces URL (or type 'exit' to quit): https://codeforces.com/problemset/problem/2046/D\n",
      "Saved page source to 'debug_page_source.html'.\n",
      "Scraped data saved to 'problems' folder.\n",
      "JSON: problems/2046/D.json\n",
      "Text: problems/2046/D.txt\n",
      "\n",
      "Enter the Codeforces URL (or type 'exit' to quit): https://codeforces.com/problemset/problem/2046/E1\n",
      "Saved page source to 'debug_page_source.html'.\n",
      "Scraped data saved to 'problems' folder.\n",
      "JSON: problems/2046/E1.json\n",
      "Text: problems/2046/E1.txt\n",
      "\n",
      "Enter the Codeforces URL (or type 'exit' to quit): https://codeforces.com/problemset/problem/2046/E2\n"
     ]
    }
   ],
   "source": [
    "# Main loop to continuously ask for URLs\n",
    "while True:\n",
    "    url = input(\"\\nEnter the Codeforces URL (or type 'exit' to quit): \")\n",
    "    if url.lower() == \"exit\":\n",
    "        print(\"Exiting the scraper. Goodbye!\")\n",
    "        break\n",
    "    scrape_codeforces(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a034cb16",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
